
<!DOCTYPE html>
<html>
<head>
    <title>Data Lake (Hadoop) Security SME-IL</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <div class="container">
        <header>
            <h1>Sun Power Consulting (SPC) is looking for Data Lake (Hadoop) Security SME-IL!</h1>
            <h2>Contract Corp-To-Corp, Contract Independent, Contract W2, C2H Corp-To-Corp, C2H Independent, C2H W2, 6 + months | Chicago, IL</h2>
            <h2>DW,BI,Reporting,Authentication,Authorization,Audit,Hadoop( Hive,Hbase,Storm) Data Governance,Hortonworks,Healthcare</h2>
        </header>
        <main>
            <p id="jobDescription"><br>Additional Information:<br>Data Lake ( Hadoop)Security SME is required in downtown Chicago. Only Candidates authorized to work for any employers are encouraged for this role. This is a very Sr. role requiring in depth knowledge in Data Security related to Hadoop. Location: Chicago, IL (Downtown)Rate: Open w2/1099/c2c Start Date: ASAPLength of Contract: 6-month+Interview process: PH + Skype + inperson Attached is a detailed description: Required Technical Skills and Experience:10 plus years of experience;3 to 5 years of Hadoop experience;Healthcare experience;Regulated data environments;Demonstrable background in enterprise data management / data security of any kind Guiding the team on Emerging Data Lake The emerging data lake will support a broad spectrum on needs including: 1) operational processes, 2) BI and 3) integrations with the broader data eco-system which includes warehouses, ODSs, data marts, etc. Candidates need to have consulting experience and the ability to work with the project team and client project participants from line workers to executive level individuals. Industry Expertise· Previous experience in a regulated environment required· Previous experience implementing process and technology controls to meet HIPAA-HITECH regulations as they apply to e PHI. Technology Expertise * Prior experience with Data Warehouses in an Enterprise Environment strongly preferred* Prior experience with Business Intelligence / Enterprise Reporting packages strongly preferred* Understanding of role-based access control concepts and Authentication, Authorization, and Audit requirements in an enterprise environment* Deep understanding of Enterprise Data Workflows including ETL concepts required* Prior experience integrating with enterprise LDAP preferred* Prior experience with data masking and data tokenization required Product Specific Knowledge * Knowledge of Hortonworks Hadoop Platform required, including: * Data Platform components: HDFS, Pig, Hive, Hbase, Storm, Solr * Data Security Components: Ambari, Ranger, Knox, Atlas * Data Lifecycle and Data Governance components: Falcon and Atlas * Hortonworks HDPCA certification or equivalent strongly preferred * Experience integrating with IBM Optim for healthcare data tokenization strongly preferre<br>Responsibilities:• <br>Qualifications:• d</p>
        </main>
    </div>
    <script src="script.js"></script>
</body>
</html>
    