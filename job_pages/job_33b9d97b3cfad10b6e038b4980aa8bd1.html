
<!DOCTYPE html>
<html>
<head>
    <title>Data Architect</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <div class="container">
        <header>
            <h1>TRIAD Group is looking for Data Architect!</h1>
            <h2>Full Time, perm | Seattle, WA</h2>
            <h2>Data, SQL, ETL, AWS, MPP, Reshift, Terdata, Vertica, Netezza, MapReduce, Hadoop, Pig, Hive, NoSQL, Python</h2>
        </header>
        <main>
            <p id="jobDescription"><br>Additional Information:<br>Data Architect Location: Seattle, WACompensation: Deluxe compensation package (Huge Base + Bonus + Sign-on Bonus + Excellent benefits)Duration: Perm/Direct Placement Start Date: ASAPOur Seattle client is looking for a talented Data Architect to join it's data and analytics platform team. You will play a key role in defining and executing an end-to-end vision that transforms numerous sources of data to usable, performant assets that support various workloads for our data scientists and analysts. PRIMARY RESPONSIBILITIES:Design/Build/Maintain all aspects of the underlying data science and analytics data warehouse/data marts. Write, maintain, monitor and improve the logic processing of billions of records Cross-functional data integration efforts, both upstream and downstream Work with the engineering team to continuously acquire new data, detect and fix data quality issues Develop and optimize ETL processes by working closely with multiple data partners and stakeholders across the company to meet growing business needs. REQUIREMENTS:Passionate about data and technology and extremely curious Great attention to detail, thinking through downstream effects of data architecture on data mining business intelligence and analysis, as well as preemptively diagnosing potential pain points for stakeholders Strong, recent, hands on expertise in data architecture and programming Strong data modeling background Working knowledge of Python, strong SQL experience Production support ETL experience Excellent communication skills: written, verbal and presentation skill is a must Flexibility and comfort working in a dynamic organization with minimal documentation and process PREFERRED QUALIFICATIONS:You’ve worked with Amazon Web Services (AWS) technologies MPP/columnar distributed databases (Redshift, Teradata, Vertica, Netezza, etc)Extensive experience working with distributed computing tools, such as Map Reduce, Hadoop, Pig, Hive or other No SQL or scripting experience You have a BS/MS/Ph D in Computer Science or related field. Qualified candidates - Please select "apply now" and send us an updated resume. Keywords:Data, SQL, ETL, AWS, MPP, Reshift, Terdata, Vertica, Netezza, Map Reduce, Hadoop, Pig, Hive, No SQL, Pytho<br>Responsibilities:• <br>Qualifications:• n</p>
        </main>
    </div>
    <script src="script.js"></script>
</body>
</html>
    