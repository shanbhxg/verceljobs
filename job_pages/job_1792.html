
    <html>
    <head>
        <title>Data Analyst</title>
        <link rel="stylesheet" href="styles.css">
    </head>
    <body>
        <h1>Forage AI</h1>
        <h2>Bengaluru, Karnataka</h2>
        <p>About the job Join Forage AI as a Data Engineer  In this 100% remote role  you’ll be working with an amazingly passionate and talented team of engineers anddata scientists who are working at the bleeding edge of data science and data automation. Responsibilities:Our data engineering team is integral to our business operation in growing through data extraction. You will play a key role in coding and designing unique data extraction methodologies. You will also have responsibilities in aiding the business growth through technological developments. You will have end-to-end ownership in working on projects independently. Here’s what you’ll do:Create and maintain an effective data pipeline architecture.Build  improve  and run our generic robots to extract data from the web while handling critical information in a wide variety of structures and formats without errorAssemble large and complex data sets based on business requirements.Set up processes (manual and automation) for optimizing data delivery at scale.Independently ensure that delivery cycles are completed end-to-end through effective collaboration with various stakeholders  including our clients  engineers  and QA specialists.Monitor and improve back-end performance.Will be responsible for handling data and problem-solving with databases and python. Requirements:Must have 3-5 years of experience working with Python programming and various python librariesMust be deeply familiar with web crawling which must include exposure to python packages and frameworks like Requests  Scrapy  Pandas  Urllib  or BeautifulSoup (BS4). Experience with web-based automation tools (Selenium  Puppeteer  or Mechanize  etc.) would be an added advantage.Must have experience in handling projects independently and delivering end-to-end solutions.Must have some exposure to working with cloud platforms  preferably AWS.Must be familiar with API development  including web frameworks like FLASK  or Django  or FastAPI  etc. and handling large volumes of data using python.Have experience in working with at least one standard RDBMS  preferably PostgreSQL. Knowledge of MongoDB would be an added advantage.Excellent troubleshooting and debugging skills.Strong attention to detail and demonstrated ability in a professional  programming position.Experience with core backend development including crafting ETL pipelines that handle large volumes of data  working in Linux environments  etc. would be an added advantage.Experience with queue-based technologies like RabbitMQ or Apache Kafka or Apache Airflow or Celery or ELK-stack (elastic search  logstash  kibana) would be an added advantage.Experience with containerization using either Docker or Kubernetes would be an added advantage. Other Infrastructure Requirements:Since this is a completely work-from-home position  you will also require the following -High-speed internet connectivity for video calls and efficient work.Capable business-grade computer (e.g.  modern processor  8 GB+ of RAM  and no other obstacles to interrupted  efficient work).Headphones with clear audio quality.Stable power connection and backups in case of internet/power failure.</p>
    </body>
    </html>
    