
<!DOCTYPE html>
<html>
<head>
    <title>Big Data solution architect</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <div class="container">
        <header>
            <h1>Prairie Consulting Services, Inc is looking for Big Data solution architect!</h1>
            <h2>Contract Corp-To-Corp, Contract Independent, Contract W2, 18 months | Chicago, IL</h2>
            <h2>Big Data, Coludera, Hadoop</h2>
        </header>
        <main>
            <p id="jobDescription"><br>Additional Information:<br>Excellent contract opportunity for a Big Data Architect to join one of the premier financial organizations in downtown Chicago – Minutes away from the union station !!! Big Data Solutions Architect Looking for a Hadoop Architect with hands on experience with CDH/Cloudera distribution. GENERAL DESCRIPTION: • This is an exciting opportunity for an experienced Big Data Architect who can immediately begin to add value to the Database Engineering division. • You will be responsible for guiding the lifecycle of a Hadoop and other Big Data solutions , including requirements analysis, platform selection, technical architecture design, application design and development, testing, and deployment• We are looking for a Solutions Architect who is passionate about data and focused on building next generation Big Data applications. • You will be working with business partners and other IT departments to understand the business objectives and drive solutions that efficiently meet the needs of the business. RESPONSIBILITIES:• The Big Data Solution Architect will be responsible for guiding the full lifecycle of a Hadoop solution, including requirements analysis, governance, capacity requirements, technical architecture design (including hardware, OS, and network topology), application design, testing, and deployment.• Provide technical direction in a team that designs and develops path breaking large-scale cluster data processing systems.• Interact with domain experts, data architects, solutions architects and analytics developers to define data models for streaming input and delivering analytics output.• Design strategies and detailed approaches to integrate Hadoop with existing applications, including but not limited to Oracle, DB2 and Enterprise Data Warehouse and Data Mart applications.• Helping internal Partners develop strategies that maximize the value of their data.• Help establish thought leadership in the big data space by contributing internal papers, technical commentary to the user community. EXPERIENCE/SKILLS REQUIRED: • To succeed in this role, the candidate should have a broad set of technology skills to be able to design and build robust Hadoop solutions for big data problems and learn quickly as the industry grows.• The candidate should have significant (3+ years) Architecture experience in the Big Data/Hadoop space utilizing the Cloudera (CDH) distribution.• A record of working effectively with application teams, understanding business drivers and executing on multiple projects in varying stages of the development life cycle is important. • The candidate must also demonstrate the ability to learn new technologies quickly and be able to transfer knowledge to others. • Candidate should possess strong problem solving skills.• Demonstrate the ability to work with already established data models and naming conventions. • Excellent communication skills • Ability to work in a fast paced, team atmosphere.• Should work effectively with a minimum of direction• Be able to grasp the problem at hand and recognize appropriate approach, tools and technologies to solve it. CANDIDATE QUALIFICATIONS. • BS in Computer Science or equivalent experience• Dealing with large data sets and distributed computing• Working in the data warehousing and Business Intelligence systems• Previous experience with RDBMS platforms, Oracle 11.x. being preferred. Hands-on administration level experience with the Hadoop stack (e. g. Map Reduce, Sqoop, Pig, Hive, HBase, Flume), Spark, Kafka are a requirement.• In depth understanding of Encryption methodologies and products (CDH Native Encryption, HPE) and security is a requirement.• Deep experience in working on large linux clusters• Hands-on experience with ETL (Extract-Transform-Load) tools (e. g Informatica, Data Stage)• Hands-on experience with BI tools and reporting software (e. g. Microstrategy, Cognos)• Hands-on experience with "productionalizing" Hadoop applications (e. g. administration, configuration management, monitoring, debugging, and performance tuning)• Knowledge of cloud computing infrastructure (e. g. Amazon Web Services EC2, Elastic Map Reduce) and considerations for scalable, distributed systems<br>Responsibilities:• <br>Qualifications:• </p>
        </main>
    </div>
    <script src="script.js"></script>
</body>
</html>
    