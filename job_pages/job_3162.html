
    <html>
    <head>
        <title>Data Analyst</title>
        <link rel="stylesheet" href="styles.css">
    </head>
    <body>
        <h1>DISH Network Technologies</h1>
        <h2>Greater Bengaluru Area, Karnataka</h2>
        <p>About the job About DISH: DISH Network Technologies India Pvt. Ltd is a technology division of DISH. In India  the technology division is located in Bengaluru and Hyderabad. These centers were established in the market to provide opportunities to the world’s best engineering talent  and to further boost innovation in multimedia network and telecommunications development. The Bengaluru center is a state-of-the-art facility  which plays a crucial role in fostering innovation. One of DISH’s largest development centers outside the U.S.  we have a growing team of over 600 dynamic professionals  who are committed to delivering our vision to change the way the world communicates. With multidisciplinary expertise of our engineers  we have filed for over 200 patents in the market Job Location : Bengaluru / Hyderabad Job Duties and Responsibilities: Actively engage with other data warehouse engineers representing business needs and shepherding projects from conception to productionCreation and optimization of data engineering pipelines for analytic projectsStrong analytic capability and the ability to create innovative solutionsParticipate in the Unit Testing  defect resolution  and root cause analysis of data sources as well as actively engaged in the identification and resolution of PROD broke issues· Provide technical guidance to L1 team members and help to resolve ETL related issuesNeed to work as on call-support Desired Skills: · Engineering degree with 3 to 6 years of experience in development and production support of large Enterprise Data Warehouse in cloud data environment· Experience in developing/debugging and fixing data ingestion pipelines both real time and batch · Experience on AWS services - S3 bucket  EC2   CloudWatch   Athena  lambda  Cloudtrail  Dynamodb will be an added advantage· Experience in transforming/integrating data in Redshift/Snowflake· Strong in writing complex SQLs to ingest data into cloud data warehouses · Good hands on experience in shell scripting or python· Experience with scheduling tools - ControlM  Airflow   StepFunction· Troubleshooting of ETL jobs and addressing production issue and suggest job enhancements· Perform root cause analysis (RCA) for failures· Good Communication skills – written and verbal with the ability to understand and interact with the diverse range of stakeholders . Capable of working without much supervision</p>
    </body>
    </html>
    