
<!DOCTYPE html>
<html>
<head>
    <title>Data Analyst</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <div class="container">
        <header>
            <h1>Uplers is looking for Data Analyst!</h1>
            <h2>Remote | Contract | 105 applicants |  Mid-Senior level</h2>
            <h2>Bengaluru, Karnataka</h2>
        </header>
        <main>
            <p id="jobDescription">
Additional Information:
Uplers is the talent powerhouse of India. Our talent ecosystem connects the right talents with the right opportunities. We matchmake the top 3.5% talents in India with global companies and pay 1.5x higher than the local salary standards. We are creating a new wave in remote hiring by helping companies hire from a strong network of top talents from India for the world. We are a catalyst to every candidate looking out for a once-in-a-lifetime opportunity to work for global companies. Join the community of India’s best talents and work remotely for global brands at a global pay scale! Job Title: Data Engineer Employment Type: Contract USA Client Contract Duration: 12 months Location: Remote Shift Timings: 2:30 PM - 11:30 PM IST Device: You have to use your own device. Required configurations and setting will be provide by us. Background Check: As a part on onboarding process there would be thorough background check verification required which includes Identity Check, Address Verification and Criminal check. Data Engineer The Role Client is seeking a Senior Data Engineer to join our team. As a remote member of the data engineering and analytics team, you will be in a position to directly impact how a client harnesses its first-party data from various sources to generate business value. This impactful position enables clients to coordinate and integrate with 3rd party data sets and proprietary data to produce valuable insights into business and customers' needs. Who You Are You are deeply passionate about organizing and managing data. You believe and understand the value that powerful reporting and analytics can drive for the business. You possess a structured and detail-oriented approach to solving problems using a diverse and resourceful technical toolkit. You are able to collaborate cross-functionally, communicating regular updates. Leading projects should come easily to you. You must advocate for positive change for efficiency and value-added capabilities. What You'll Be Doing Create and maintain optimal data pipeline architecture Assist in building a high performing data platform which will power various reporting and analytics applications at client Create data tools for analytics and data team members that assist them in building and optimizing data models and metrics Proactively research and contribute ideas for improvement of data team processes Produce scalable, replicable code and engineering solutions that help automate repetitive processes Productionize data and machine learning models by creating and maintaining microservices to expose data to the application using Python, Dynamo DB, Flask, and Graph QL What You'll Bring to the Team Expertise and hands-on experience working in a cloud based data stack (AWS preferred)Expertise in developing and maintaining relational database structures and relationships Expertise writing processing jobs to ingest a variety of structured and unstructured data received from various sources & formats such as Rest APIs, Flat Files, Logs Hands on experience using non-relational database technologies and comfort shepherding adoption of these tools by less experienced developers Expert level skills in using Python for data processing coupled with AWS cloud services Expert level skills in writing & managing optimized SQL for creating, updating and querying source of truth tables We are looking for a candidate with 5+ years of experience in a Data Engineer role. They should also have experience using the following software/tools:Experience with relational SQL and No SQL databases such as Redshift or comparable cloud-based OLAP databases such as Snowflake Experience with data pipeline and workflow management tools: Airflow Experience with object oriented and functional python programming Experience with technologies such as Dynamo, Terraform, Kubernetes, Fivetran, Graph QL, and dbt is a strong plus Comfortable working in a fast-paced growth business with many collaborators and quickly evolving business need

Responsibilities:• 

Qualifications:• s</p>
        </main>
    </div>
    <script src="script.js"></script>
</body>
</html>
    