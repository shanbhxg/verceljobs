
    <html>
    <head>
        <title>Data Analyst</title>
        <link rel="stylesheet" href="styles.css">
    </head>
    <body>
        <h1>Spiralogics, Inc.</h1>
        <h2>Bengaluru, Karnataka</h2>
        <p>About the job Job Summary:Spiralogics is a leading custom software development company primarily based in the US  Nepal and India. With 18+ years of experience in the tech industry  we go beyond the traditional application development process to deliver quality products. With an array of both in-house and client-based applications  we work with different technologies such as Dot NET  PHP  Python  Node JS  React  Angular JS  Java  Xamarin  iOS  Android  Flutter. We are looking for a savvy AWS Data Engineer to join our growing team of analytic experts. The hire will be responsible for expanding and optimizing our data and data pipeline architecture  as well as optimizing data flow and collection for cross-functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Engineer will support our software developers  database architects  data analysts  and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams  systems  and products. The right candidate will be excited by the prospect of optimizing or even re-designing our companyâ€™s data architecture to support our next generation of products and data initiatives. To give you a sense of what we expect  here is a link [career.spiralogics.com] to our own career portal where we constantly add new positions that may better fit you. Responsibilities for Data EngineerCreate and maintain optimal data pipeline architecture Assemble large  complex data sets that meet functional / non-functional business requirements.Identify  design  and implement internal process improvements: automating manual processes  optimizing data delivery  re-designing infrastructure for greater scalability  etc.Build the infrastructure required for optimal extraction  transformation  and loading of data from a wide variety of data sources using SQL and AWS technologies.Build analytic tools that utilize the data pipeline to provide actionable insights into customer acquisition  operational efficiency  and other key business performance metrics.Work with stakeholders including the Executive  Product  Data  and Design teams to assist with data-related technical issues and support their data infrastructure needs.Keep our data separated and secure across national boundaries through multiple data centers and AWS regions.Create data tools for analytic and data scientist team members that assist them in building and optimizing ourproduct into an innovative industry leader.Work with data and analytic experts to strive for greater functionality in our data systems. Qualifications for Data EngineerAdvanced working SQL knowledge and experience working with relational databases  query authoring (SQL) as well as working familiarity with a variety of databases.Experience building and optimizing data pipelines  architectures  and data sets.Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.Strong analytic skills related to working with unstructured datasets.Build processes supporting data transformation  data structures  metadata  dependency  and workload management.A successful history of manipulating  processing  and extracting value from large disconnected datasets.Strong project management and organizational skills.Experience supporting and working with cross-functional teams in a dynamic environment.We are looking for a candidate with 5+ years of experience in a Data Engineer role  who has attained a Graduate degree in Computer Science  Statistics  Informatics  Information Systems  or another quantitative field. They should also have experience using the following software/tools:Experience with Python and Pyspark.Experience with relational SQL and NoSQL databases  including Postgres and Cassandra.Experience with data pipeline and workflow management tools: Airflow  etc.Experience with AWS cloud services: EC2  EMR  RDS  Redshift  Glue  Lambda.Experience with object-oriented/object function scripting languages: Python  Pyspark Data Engineering & API Focusa) AWS Cloud ServicesStorage: S3  RDSCompute: Glue  Lambdab) Python3.6 & abovec) Sparkd) SQLe) REST APIf) OpenID Connect & OAuth 2.0 API Must Know: AWS/Services  Pyspark  python  lambda  kinesis  RDS data services  data pipeline</p>
    </body>
    </html>
    