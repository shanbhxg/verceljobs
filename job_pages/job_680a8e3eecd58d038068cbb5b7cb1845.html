
<!DOCTYPE html>
<html>
<head>
    <title>Big Data Engineer Consultant</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <div class="container">
        <header>
            <h1>Applied Resource Group is looking for Big Data Engineer Consultant!</h1>
            <h2>Full Time | Dallas, TX</h2>
            <h2>NoSQL, Consultanta, Data Engineer, Hadoop, Architecture, Data Acquisitions, Data Storage, Data Management</h2>
        </header>
        <main>
            <p id="jobDescription"><br>Additional Information:<br>Big Data Engineer Consultant Data Engineers at the Consultant level will be responsible for architecture, design and implementation of Hadoop and No SQL based full scale solutions that includes data acquisition, storage, transformation, security, data management and data analysis using these technologies. A solid understanding of infrastructure planning, scaling, design and operational considerations that are unique to Hadoop, No SQL and other emerging data technologies is required. We are looking for candidates who have a broad set of technology skills across these areas and who can demonstrate an ability to identify and apply Hadoop and No SQL solutions to challenges with data and provide better data solutions to industries. Basic Qualifications Bachelor's degree in Computer Science, Engineering, Technical Science or 3 years of IT/Programming experience Minimum 2+ years of building and deploying applications java applications in a Linux/Unix environment. Minimum of 1+ years designing and building large scale data loading, manipulation, processing, analysis, blending and exploration solutions using Hadoop/No SQL technologies (e. g. HDFS, Hive, Sqoop, Flume, Spark, Kafka, HBase, Cassandra, Mongo DB etc.)Minimum 1+ years of architecting and organizing data at scale for a Hadoop/No SQL data stores Minimum 1+ years of coding with Map Reduce Java, Spark, Pig, Hadoop Streaming, Hive QL, Perl/Python/PHP for data analysis of production Hadoop/No SQL applications Preferred Skills Minimum 2 years designing and implementing relational data models working with RDBMS move to preferred Minimum 2 years working with traditional as well as Big Data ETL tools move to preferred Minimum 2 years of experience designing and building REST web services move to preferred Designing and building statistical analysis models, machine learning models, other analytical modeling using these technologies on large data sets (e. g. R, MLib, Mahout, Spark, Graph X) move to preferred Minimum 1 year of experience implementing large scale cloud data solutions using AWS data services e. g. EMR, Redshift move to preferred2+ years of hands-on experience designing, implementing and operationalizing production data solutions using emerging technologies such as Hadoop Ecosystem (Map Reduce, Hive, HBase, Spark, Sqoop, Flume, Pig, Kafka etc.), No SQL(e. g. Cassandra, Mongo DB), In-Memory Data Technologies, Data Munging Technologies. Architecting large scale Hadoop/No SQL operational environments for production deployments Designing and Building different data access patterns from Hadoop/No SQL data stores Managing and Modeling data using Hadoop and No SQL data stores Metadata management with Hadoop and No SQL data in a hybrid environment Experience with data munging / data wrangling tools and technologie<br>Responsibilities:• <br>Qualifications:• Bachelor's degree in Computer Science, Engineering, Technical Science or 3 years of IT/Programming experience Minimum 2+ years of building and deploying applications java applications in a Linux/Unix environment<br>• Minimum of 1+ years designing and building large scale data loading, manipulation, processing, analysis, blending and exploration solutions using Hadoop/No SQL technologies (e<br>• g<br>• HDFS, Hive, Sqoop, Flume, Spark, Kafka, HBase, Cassandra, Mongo DB etc<br>• )Minimum 1+ years of architecting and organizing data at scale for a Hadoop/No SQL data stores Minimum 1+ years of coding with Map Reduce Java, Spark, Pig, Hadoop Streaming, Hive QL, Perl/Python/PHP for data analysis of production Hadoop/No SQL applications Preferred Skills Minimum 2 years designing and implementing relational data models working with RDBMS move to preferred Minimum 2 years working with traditional as well as Big Data ETL tools move to preferred Minimum 2 years of experience designing and building REST web services move to preferred Designing and building statistical analysis models, machine learning models, other analytical modeling using these technologies on large data sets (e<br>• g<br>• R, MLib, Mahout, Spark, Graph X) move to preferred Minimum 1 year of experience implementing large scale cloud data solutions using AWS data services e<br>• g<br>• EMR, Redshift move to preferred2+ years of hands-on experience designing, implementing and operationalizing production data solutions using emerging technologies such as Hadoop Ecosystem (Map Reduce, Hive, HBase, Spark, Sqoop, Flume, Pig, Kafka etc<br>• ), No SQL(e<br>• g<br>• Cassandra, Mongo DB), In-Memory Data Technologies, Data Munging Technologies<br>• Architecting large scale Hadoop/No SQL operational environments for production deployments Designing and Building different data access patterns from Hadoop/No SQL data stores Managing and Modeling data using Hadoop and No SQL data stores Metadata management with Hadoop and No SQL data in a hybrid environment Experience with data munging / data wrangling tools and technologies</p>
        </main>
    </div>
    <script src="script.js"></script>
</body>
</html>
    