
<!DOCTYPE html>
<html>
<head>
    <title>Data Analyst</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <div class="container">
        <header>
            <h1>Asper.ai is looking for Data Analyst!</h1>
            <h2>On-site | Full-time | 0 applicants |  Mid-Senior level</h2>
            <h2>Bengaluru, Karnataka</h2>
        </header>
        <main>
            <p id="jobDescription">Additional Information:
About Asper. Ai Asper. ai, a Fractal company, enables interconnected and automated decisions at the intersection of demand and supply. By changing the way decisions are made, Asper. ai unlocks growth and transforms organizations into adaptive intelligent enterprises. Through its 'autonomic decisioning' platform, Asper. ai works with data to not just provide proactive decisions but to provide interconnected and automated decisions that help customers reach their true potential – from their bottom-line results to optimize their workflows. Website. SUMMARY: Seeking individuals with demonstrated experience in data engineering for architecting, developing and maintaining configurable and scalable enterprise data engineering modules and pipelines. Your primary focus will be architecting, developing, enhancing and optimizing data engineering pipelines. You will also be responsible for leading the data function, data strategy, data transformation and change. RESPONSIBILITIES: ● Architect the DE pipelines with scalability, configurability and security● Develop and deploy scalable and configurable data engineering pipelines● Lead the data function and set out data strategy and roadmap● Manage stakeholder relationship at all levels and understand and align their data requirements● Lead the development, publication and maintenance of design documents and roadmaps● Review, audit and improve the Data Engineering code base and pipelines● Support maintenance of deployed pipelines (bug-fixes and performance improvement)● Participate in organization building activities (team mentoring, cross team training & hiring . TECHNICAL SKILLS: ● Data structure and algorithm● Data modelling and design● Excellent Coding skills in Python and SQL.● Excellent understanding of Pandas API● Experience of writing/maintaining Spark code base in a production environment.● Experience in orchestration technologies like Airflow, Kubeflow etc.● Experience on running ETL pipelines from a wide variety of sources, both batch & streaming, using latest data frameworks and technologies with real time monitoring and alerting.● Essential experience of working with distributed systems software development.● Critical experience in performance optimization for both data loading and ingestion.● Know-how of critical developer’s toolkit such as Linux, Git Hub, Dockers, VSCode, Jupyter● Ability to work in a fast-paced and deadline driven environment.● Experience of working on public clouds (AWS / Azure
Responsibilities:• Qualifications:• )</p>
        </main>
    </div>
    <script src="script.js"></script>
</body>
</html>
    