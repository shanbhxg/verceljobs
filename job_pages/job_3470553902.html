
<!DOCTYPE html>
<html>
<head>
    <title>Data Analyst</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <div class="container">
        <header>
            <h1>Analytics Saves at Work is looking for Data Analyst!</h1>
            <h2>On-site | Full-time | 4 applicants | Not Avilable</h2>
            <h2>Bengaluru, Karnataka</h2>
        </header>
        <main>
            <p id="jobDescription">Additional Information:
Job Description Location - Bangalore Analytics Saves at Work is looking for exceptional Data Engineers for one of our clients which is a fortune 50 company, headquarter in US. The Data Engineer will be responsible for delivering business needs end-to-end, starting from understanding the requirements to deploying the software into production. This role requires being fluent in some technologies while being proficient in others while learning on the job to deliver value to both customers and to the business. In addition to delivery, the Data Engineers should have an automation first and continuous improvement mindset, driving the adoption of CI/CD tools while supporting the improvement of the toolsets/processes. Skills, Qualifications, and Certifications: • Bachelor’s degree or equivalent experience required; a degree in a quantitative discipline: statistics, applied mathematics, computer science, data mining, machine learning.• 3 to 8 years of IT experience / relevant experience• AWS Cloud certifications, and/or cloud development experience with developing applications or infrastructure on AWS• Documented experience in business intelligence, ETL or analytic development role on a variety of large-scale projects (3 years minimum)• Knowledge of Apache Spark, distributed application development on spark using Py Spark or Scala, and familiarity with other Hadoop ecosystems such as Yarn, Hive, Oozie, Impala Analyse and rearchitect and re-platform on-premises data platform to AWS. • Design-Build and operationalize large scale enterprise using one or more AWS data and analytical services – Spark, EMR, Dynamo DB, Redshift, Kinesis, Lambda, Glue. • Experience in development using scripting languages such as Python.• Dev Ops, CICD development experience is a plus• Experience in deploying applications using Docker and/or Kubernetes• Comfortable in configuring and using multiple operating systems (Mac/Windows/*nix)• Design and architecture expertise with AWS, Hadoop, Teradata, BI, and related ecosystem tools.• Knowledge of statistical languages such as SAS, R or Python with Sci Py/Num Py Candidate should have:• A passion for healthcare and the potential for technology to improve people’s lives• The aptitude to deliver enterprise or customer-facing applications in a variety of scenarios• A deep understanding of environmental constraints to implementing and deploying differing application solutions • Proven track record of quality software development and an ability to innovate outside of traditional architecture/software patterns when needed• A desire to collaborate in a high-performing team environment, and an ability to influence and be influenced by others• Experience in helping distil complex ideas into an architectural and implementation plan, and then proving it out • The ability to critically evaluate the trade-offs and implementation impacts of emerging vs. more established technologies Notice Period - 2 months/preferred 45 days
Responsibilities:• Qualifications:• , and Certifications: • Bachelor’s degree or equivalent experience required; a degree in a quantitative discipline: statistics, applied mathematics, computer science, data mining, machine learning
• • 3 to 8 years of IT experience / relevant experience• AWS Cloud certifications, and/or cloud development experience with developing applications or infrastructure on AWS• Documented experience in business intelligence, ETL or analytic development role on a variety of large-scale projects (3 years minimum)• Knowledge of Apache Spark, distributed application development on spark using Py Spark or Scala, and familiarity with other Hadoop ecosystems such as Yarn, Hive, Oozie, Impala Analyse and rearchitect and re-platform on-premises data platform to AWS
• • Design-Build and operationalize large scale enterprise using one or more AWS data and analytical services – Spark, EMR, Dynamo DB, Redshift, Kinesis, Lambda, Glue
• • Experience in development using scripting languages such as Python
• • Dev Ops, CICD development experience is a plus• Experience in deploying applications using Docker and/or Kubernetes• Comfortable in configuring and using multiple operating systems (Mac/Windows/*nix)• Design and architecture expertise with AWS, Hadoop, Teradata, BI, and related ecosystem tools
• • Knowledge of statistical languages such as SAS, R or Python with Sci Py/Num Py Candidate should have:• A passion for healthcare and the potential for technology to improve people’s lives• The aptitude to deliver enterprise or customer-facing applications in a variety of scenarios• A deep understanding of environmental constraints to implementing and deploying differing application solutions • Proven track record of quality software development and an ability to innovate outside of traditional architecture/software patterns when needed• A desire to collaborate in a high-performing team environment, and an ability to influence and be influenced by others• Experience in helping distil complex ideas into an architectural and implementation plan, and then proving it out • The ability to critically evaluate the trade-offs and implementation impacts of emerging vs
• more established technologies Notice Period - 2 months/preferred 45 days</p>
        </main>
    </div>
    <script src="script.js"></script>
</body>
</html>
    