
<!DOCTYPE html>
<html>
<head>
    <title>Data Analyst</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <div class="container">
        <header>
            <h1>Forage AI is looking for Data Analyst!</h1>
            <h2>Remote | Full-time | 0 applicants | Not Avilable</h2>
            <h2>Bengaluru, Karnataka</h2>
        </header>
        <main>
            <p id="jobDescription"><br>Additional Information:<br>Join Forage AI as a Data Engineer! In this 100% remote role, you’ll be working with an amazingly passionate and talented team of engineers anddata scientists who are working at the bleeding edge of data science and data automation.<br>Responsibilities:• :Our data engineering team is integral to our business operation in growing through data extraction<br>• You will play a key role in coding and designing unique data extraction methodologies<br>• You will also have responsibilities in aiding the business growth through technological developments<br>• You will have end-to-end ownership in working on projects independently<br>• Here’s what you’ll do:Create and maintain an effective data pipeline architecture<br>• Build, improve, and run our generic robots to extract data from the web while handling critical information in a wide variety of structures and formats without error Assemble large and complex data sets based on business requirements<br>• Set up processes (manual and automation) for optimizing data delivery at scale<br>• Independently ensure that delivery cycles are completed end-to-end through effective collaboration with various stakeholders, including our clients, engineers, and QA specialists<br>• Monitor and improve back-end performance<br>• Will be responsible for handling data and problem-solving with databases and python<br>• Requirements:Must have 3 5 years of experience working with Python programming and various python libraries Must be deeply familiar with web crawling which must include exposure to python packages and frameworks like Requests, Scrapy, Pandas, Urllib, or Beautiful Soup (BS4)<br>• Experience with web-based automation tools (Selenium, Puppeteer, or Mechanize, etc<br>• ) would be an added advantage<br>• Must have experience in handling projects independently and delivering end-to-end solutions<br>• Must have some exposure to working with cloud platforms, preferably AWS<br>• Must be familiar with API development, including web frameworks like FLASK, or Django, or Fast API, etc<br>• and handling large volumes of data using python<br>• Have experience in working with at least one standard RDBMS, preferably Postgre SQL<br>• Knowledge of Mongo DB would be an added advantage<br>• Excellent troubleshooting and debugging skills<br>• Strong attention to detail and demonstrated ability in a professional, programming position<br>• Experience with core backend development including crafting ETL pipelines that handle large volumes of data, working in Linux environments, etc<br>• would be an added advantage<br>• Experience with queue-based technologies like Rabbit MQ or Apache Kafka or Apache Airflow or Celery or ELK-stack (elastic search, logstash, kibana) would be an added advantage<br>• Experience with containerization using either Docker or Kubernetes would be an added advantage<br>• Other Infrastructure Requirements:Since this is a completely work-from-home position, you will also require the following -High-speed internet connectivity for video calls and efficient work<br>• Capable business-grade computer (e<br>• g<br>• , modern processor, 8 GB+ of RAM, and no other obstacles to interrupted, efficient work)<br>• Headphones with clear audio quality<br>• Stable power connection and backups in case of internet/power failure<br>Qualifications:• </p>
        </main>
    </div>
    <script src="script.js"></script>
</body>
</html>
    