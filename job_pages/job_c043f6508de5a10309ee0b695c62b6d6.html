
<!DOCTYPE html>
<html>
<head>
    <title>Data Engineer</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <div class="container">
        <header>
            <h1>Amazon is looking for Data Engineer!</h1>
            <h2>Full Time | Seattle, WA</h2>
            <h2>Analysis, Automated, Business Intelligence, Database, Data Modeling, Data Warehouse, Development, Hadoop, Java, Linux, Management, Metrics, Modeling, Research, Scripts, SQL, Statistical Analysis</h2>
        </header>
        <main>
            <p id="jobDescription"><br>Additional Information:<br>Are you ready to take your career to the next level? How would you like to be the driving force for developing data solutions for a world-class business intelligence platform powered by Amazon Web Services (AWS) including Amazon Redshift? If you answered yes, then the Fraud Prevention Team at AWS is looking for you! The mission of the Fraud Prevention Team is to keep the AWS platform a safe and trusted place for our customers and partners. We achieve this goal by identifying and preventing fraud for all AWS services, worldwide. Every day fraudsters attempt to steal our services. We use extensive data modeling, machine learning and software solutions to identify the good from the bad so that we can protect AWS users. As a Data Engineer, you will utilize database technologies, including SQL, ETL and Redshift. You will design, develop, and evaluate highly innovative business intelligence tools. You will develop automated reports for fraud detection and prevention. You will constantly be seeking out new data that is useful in improving fraud prevention at AWS. You will determine how to make this information available to enable the development and production of a world class fraud prevention platform. As a Data Engineer, you will also support senior management by developing and managing metrics reporting. We are raising the bar for Fraud prevention in the Cloud. This is ground floor opportunity where a successful candidate will have the ability to shape and define fraud prevention. The position requires deep expertise in the design, creation, management, and business use of large datasets. You should have excellent communication skills and be comfortable working with business owners to understand data formats, requirements, and be able to work independently to build ETL to make the data available to our research scientists. You should be an expert at designing, implementing, and operating stable, scalable, low cost solutions to flow data from production systems into a data warehouse and ultimately into end-user facing reporting applications. Above all, you should be passionate about working with huge data sets, doesn't mind getting involved in details, is willing to be creative and wants a role that has a direct and measurable impact on the business. Basic Qualifications * This position requires a Bachelor's Degree in Computer Science or a related technical field, and 4+ years experience. * Experience with ETL, Data Modeling, and working with Business Intelligence systems * Expert in writing SQL scripts. * Experience with processing large, multi-dimensional datasets from multiple source * Experience in monitoring and automated reporting. * Solid Linux skills. Preferred Qualifications * MS or Ph D in CS or another quantitative field * Experience processing large, multi-dimensional datasets * Experience with MPP databases such as Redshift * Experience with Java and Map Reduce frameworks such as Hive/Hadoop * Solid communication skills and team player * A passion for technology * Someone who is keen to leverage their existing skills while trying new approaches * Previous work with statistical analysis Posted Date: 10/10/2016 6:50:25 P<br>Responsibilities:• <br>Qualifications:• * This position requires a Bachelor's Degree in Computer Science or a related technical field, and 4+ years experience<br>• * Experience with ETL, Data Modeling, and working with Business Intelligence systems * Expert in writing SQL scripts<br>• * Experience with processing large, multi-dimensional datasets from multiple source * Experience in monitoring and automated reporting<br>• * Solid Linux skills<br>• Preferred  * MS or Ph D in CS or another quantitative field * Experience processing large, multi-dimensional datasets * Experience with MPP databases such as Redshift * Experience with Java and Map Reduce frameworks such as Hive/Hadoop * Solid communication skills and team player * A passion for technology * Someone who is keen to leverage their existing skills while trying new approaches * Previous work with statistical analysis Posted Date: 10/10/2016 6:50:25 PM</p>
        </main>
    </div>
    <script src="script.js"></script>
</body>
</html>
    